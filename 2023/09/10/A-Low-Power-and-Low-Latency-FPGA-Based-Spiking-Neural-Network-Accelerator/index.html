<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"/><meta name="theme-color" content="#222"/><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"/><meta name="renderer" content="webkit"/><link rel="icon" type="image/ico" sizes="32x32" href="/assets/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"/><link rel="alternate" href="/rss.xml" title="NightFury" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="NightFury" type="application/atom+xml"><link rel="alternate" type="application/json" title="NightFury" href="https://nightfury.top/feed.json"/><link rel="preconnect" href="https://mirrors.sustech.edu.cn/cdnjs"/><link rel="preconnect" href="https://cdnjs.snrat.com"/><link rel="preconnect" href="https://s4.zstatic.net"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/app.css?v=0.4.17"><link rel="modulepreload" href="/js/chunk-EWPEWLLZ.js"></link><link rel="modulepreload" href="/js/chunk-FJIYN5II.js"></link><link rel="modulepreload" href="/js/chunk-M4X3XC6X.js"></link><link rel="modulepreload" href="/js/chunk-RPQFIKYV.js"></link><link rel="modulepreload" href="/js/chunk-U5IFKWJQ.js"></link><link rel="modulepreload" href="/js/chunk-WIQECBEN.js"></link><link rel="modulepreload" href="/js/comments-FXTJC3OS.js"></link><link rel="modulepreload" href="/js/copy-tex-SNESBJPB.js"></link><link rel="modulepreload" href="/js/index.esm-KW346CBT.js"></link><link rel="modulepreload" href="/js/post-S7HGICWK.js"></link><link rel="modulepreload" href="/js/quicklink-5D6BABLD.js"></link><link rel="modulepreload" href="/js/search-IUFG55LJ.js"></link><link rel="modulepreload" href="/js/siteInit.js"></link><link rel="modulepreload" href="/js/waline-BZCX4Z63.js"></link><link rel="stylesheet" href="/css/comments-3DIOODFJ.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/waline-RZIHPP7A.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="preload" href="/assets/cover/IEEE.webp" as="image" fetchpriority="high"><meta name="keywords" content="SNN,Hardware"/><meta name="description" content="个人笔记 &amp; 踩坑记录 &amp; 各种收藏"/><link rel="canonical" href="https://nightfury.top/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/"><title>A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator</h1><div class="meta"><span class="item" title="创建时间：2023-09-10 15:36:45"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">发表于</span><time itemprop="dateCreated datePublished" datetime="2023-09-10T15:36:45+08:00">2023-09-10</time></span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i></span><span class="text">本文字数</span><span>2.1k</span><span class="text">字</span></span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i></span><span class="text">阅读时长</span><span>2 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">NightFury's Blog</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><img src="/assets/cover/IEEE.webp" loading="eager" decoding="async" fetchpriority="high" alt="NightFury"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemListElement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">首页</a></span><i class="ic i-angle-right"></i><span itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/Paper/" itemprop="item" rel="index" title="分类于Paper"><span itemprop="name">Paper<meta itemprop="position" content="0"/></span></a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/Paper/Algorithm/" itemprop="item" rel="index" title="分类于Algorithm"><span itemprop="name">Algorithm<meta itemprop="position" content="1"/></span></a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://nightfury.top/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/"/><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/avatar.webp"/><meta itemprop="name" content="NightFury"/><meta itemprop="description" content="行动胜于空想, 个人笔记 &amp; 踩坑记录 &amp; 各种收藏"/></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="NightFury"/></span><div class="body md" itemprop="articleBody"><div class="tabs" id="summary"><div class="show-btn"></div><div class="nav"><ul class="special"></ul></div><div class="tab" data-id="summary" data-title="自我介绍"><p>我是基于Gemini-1.5-flash实现的AI助手，在此网站上负责整理和概括文章</p></div><div class="tab active" data-id="summary" data-title="文章概括"><p>本文提出了一种低功耗、低延迟的基于FPGA的脉冲神经网络（SNN）加速器。该加速器通过设计卷积池化(CONVP)单元，融合卷积层和池化层的处理，并利用内部和跨输出并行性来加速全连接层推理，从而减少延迟和资源消耗。在Zynq XA7Z020 FPGA上进行实验，结果表明该加速器在MNIST和DVSGesture数据集上分别比现有FPGA实现和ASIC设计快约28倍和15倍，同时功耗更低。  该设计采用脉冲编码，利用Adder Tree进行卷积计算，并通过优化数据流和并行处理策略提升效率。
</p></div></div><h1 id="A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator"><a href="#A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator" class="headerlink" title="A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator"></a>A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>翻译自 ChatGPT：</p>
<blockquote>
<p>脉冲神经网络（SNNs），被称为神经网络的第三代，因其生物合理性和类似大脑的特征而著名。最近的努力进一步展示了 SNN 在高速推断方面的潜力，通过设计具有时间或空间维度并行性的加速器。然而，由于硬件资源的限制，加速器设计必须利用片外内存来存储许多中间数据，这导致了高功耗和长延迟。本文侧重于层间数据流以提高算术效率。基于脉冲的离散特性，我们设计了一个卷积池化（CONVP）单元，<strong>将卷积层和池化层的处理合并</strong>，以减少延迟和资源利用率。此外，对于全连接层，我们应用了<strong>内部输出并行性和跨输出并行性</strong>来加速网络推理。我们通过在 Zynq XA7Z020 FPGA 上实现不同的 SNN 模型，并使用不同的数据集来展示我们提出的硬件架构的有效性。实验结果显示，我们的加速器在 MNIST 数据集上与 FPGA 实现相比，可以实现约 28 倍的推断速度提升，并在 DVSGesture 数据集上与 ASIC 设计相比，可以实现约 15 倍的推断速度提升，功耗较低。</p>
</blockquote>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ol>
<li>使用 <strong>rate coding</strong>，<strong>IF</strong> 神经元模型，没给出具体的时间步是多少。</li>
</ol>
<h2 id="设计方法"><a href="#设计方法" class="headerlink" title="设计方法"></a>设计方法</h2><ol>
<li><p>PC 端负责<strong>脉冲编码</strong>，通过 UART 协议输出给 PL 端；PL 端负责<strong>网络推理</strong>，<strong>对输入脉冲做 Line Buffer 做卷积（Adder Tree）</strong>，输出结果再传回 PC 端进行验证，系统框图如图：<img loading="lazy" data-src="/assets/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/%E7%B3%BB%E7%BB%9F%E6%A1%86%E5%9B%BE.png" alt="系统框图"></p>
</li>
<li><p>所谓的 CONVP 就是把 <strong>Conv 和 MaxPooling 融合</strong>（呃呃不就是很常见的多加个 buffer 吗，而且作者所做的似乎是 Valid Conv ），然后做了 <strong>Intra-Row Pooling</strong> 和 <strong>Inter-Row Pooling</strong>，说白了就是比如做 MP2 的时候，第一行先做 Intra-Row Pooling，每两个做一次 OR 操作再写入 Buffer，在第二行的时候则作 Inter-Row Pooling，本来是应该读出第一行的 pooling 结果然后接着做 OR 操作的，但作者似乎是偷懒多开了一行 Buffer 再一一做 OR 操作，如图：</p>
<p><img loading="lazy" data-src="/assets/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/MaxPooling.png" alt="MaxPooling"></p>
</li>
<li><p>卷积过程也有 <strong>Inter-Output Parallelism</strong> 和 <strong>Intra-Output Parallelism</strong>，其中 Intra-Output Parallelism 是把对某个神经元有贡献的权重（n bits）分成 k 个作为一组，即并行度为 k，经过 Ci &#x2F; k 个 Clock 后就可以算完一个输出神经元的膜电势；Intra-Output Parallelism 没怎么理解，我估计是对上个 FC 层计算完的结果直接拿来做运算，而不需要存起来再被这层 FC 取出来作为 Input，如图：<img loading="lazy" data-src="/assets/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B9%B6%E8%A1%8C%E8%8C%83%E5%BC%8F.png" alt="全连接并行范式"><img loading="lazy" data-src="/assets/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/%E5%85%A8%E8%BF%9E%E6%8E%A5%E6%9D%83%E9%87%8D%E5%AD%98%E5%82%A8.png" alt="全连接权重存储"></p>
</li>
</ol>
<h2 id="实验与评估"><a href="#实验与评估" class="headerlink" title="实验与评估"></a>实验与评估</h2><ol>
<li><p>在 Xilinx Zynq XA7Z020 FPGA 上进行了部署，Verilog 设计，8 bits 定点量化，100 MHz 时钟频率，性能对比如图：</p>
<p><img loading="lazy" data-src="/assets/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="性能对比"></p>
</li>
<li><p>其他也没啥好说的了，作者最后还对比了下 <strong>CONVP</strong> 和 <strong>CONV-POOLING</strong> 以及有无  <strong>Inter-Output Parallelism</strong> 和 <strong>Intra-Output Parallelism</strong> 的推理速率、资源使用率的差别，只能说增加了下工作量吧。</p>
</li>
</ol>
<div class="tags"><a href="/tags/SNN/" rel="tag"><i class="ic i-tag"></i>SNN</a><a href="/tags/FPGA/" rel="tag"><i class="ic i-tag"></i>FPGA</a><a href="/tags/Hardware/" rel="tag"><i class="ic i-tag"></i>Hardware</a></div></div><footer><div class="meta"><span class="icon"><i class="ic i-eye"></i></span><span>此文章已被阅读次数:</span><span class="waline-pageview-count" id="twikoo_visitors" data-path="/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/">正在加载...</span><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">更新于</span><time title="修改时间：2025-01-20 18:55:08" itemprop="dateModified" datetime="2025-01-20T18:55:08+08:00">2025-01-20</time></span></div><div id="copyright"><ul><li class="author"><strong>本文作者：</strong>NightFury<i class="ic i-at"><em>@</em></i>NightFury</li><li class="link"><strong>本文链接：</strong><a href="https://nightfury.top/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/" title="A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator">https://nightfury.top/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/</a></li><li class="license"><strong>版权声明：</strong>本站所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/" rel="prev" itemprop="url" data-background-image="&#x2F;assets&#x2F;cover&#x2F;IEEE.webp" title="Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks"><span class="type">上一篇</span><span class="category"><i class="ic i-flag"></i>Algorithm</span><h3>Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</h3></a></div><div class="item right"><a href="/2023/09/11/table/" rel="next" itemprop="url" data-background-image="&#x2F;assets&#x2F;cover&#x2F;IEEE.webp" title="table"><span class="type">下一篇</span><span class="category"><i class="ic i-flag"></i>Algorithm</span><h3>table</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator"><span class="toc-number">1.</span> <span class="toc-text">A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.2.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text">设计方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-number">1.4.</span> <span class="toc-text">实验与评估</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li ><a href="/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/" rel="bookmark" title="Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks">Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</a></li><li  class="active"><a href="/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/" rel="bookmark" title="A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator">A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator</a></li><li ><a href="/2023/09/11/table/" rel="bookmark" title="table">table</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="NightFury" src="/assets/avatar.webp"/><p class="name" itemprop="name">NightFury</p><div class="description" itemprop="description">个人笔记 & 踩坑记录 & 各种收藏</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">15</span><span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">7</span><span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">18</span><span class="name">标签</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/szNightFury" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;szNightFury"><i class="ic i-github"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li></div></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2023/09/11/table/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2023/07/27/HelloWorld/">Hello World</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2023/07/27/Php%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">Php环境配置</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2024/07/04/Debian12%E7%B3%BB%E7%BB%9FHexo%E9%83%A8%E7%BD%B2%E5%88%B0VPS/">Debian12系统Hexo部署到VPS</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2023/08/13/Sbt%E7%BC%93%E5%AD%98%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE/">Sbt缓存目录配置</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2023/08/14/Hexo%E9%83%A8%E7%BD%B2%E5%88%B0VPS/">Hexo部署到VPS</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2024/07/05/Debian12%E9%83%A8%E7%BD%B2Cloudreve%E4%BA%91%E7%9B%98/">Debian12部署Cloudreve云盘</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Technique/" title="分类于Technique">Technique</a></div><span><a href="/2023/07/27/m2sPipe%E4%B8%8Es2mPipe/">m2sPipe与s2mPipe</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Paper/" title="分类于Paper">Paper</a><i class="ic i-angle-right"></i><a href="/categories/Paper/Algorithm/" title="分类于Algorithm">Algorithm</a></div><span><a href="/2023/09/11/table/">table</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2024/07/05/%E5%88%A9%E7%94%A8Acme%E8%84%9A%E6%9C%AC%E8%87%AA%E5%8A%A8%E7%94%B3%E8%AF%B7SSL%E8%AF%81%E4%B9%A6/">利用Acme脚本自动申请SSL证书</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Algorithm/" title="分类于Algorithm">Algorithm</a><i class="ic i-angle-right"></i><a href="/categories/Algorithm/Draft/" title="分类于Draft">Draft</a></div><span><a href="/2023/08/15/Memory%20Layout%20Analysis/">Memory Layout Analysis</a></span></li></ul></div><div class="rpost pjax"><h2>最新评论</h2><ul class="leancloud-recent-comment" id="new-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2023 -<span itemprop="copyrightYear">2025</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">NightFury @ NightFury's Blog</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="站点总字数">57k 字</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="站点阅读时长">51 分钟</span></div><div class="powered-by">基于 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
        path: `2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/`,
        favicon: {
        show: `NightFury's Blog`,
        hide: `NightFury's Blog`
    },
    search: {
        placeholder: "文章搜索",
        empty: "关于 「 ${query} 」，什么也没搜到",
        stats: "${time} ms 内找到 ${hits} 条结果"
    },
    copy_tex: true,
    katex: true,
    mermaid: false,
    audio: undefined,
    fancybox: true,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">文章时效性提示</span><br>这是一篇发布于 {{publish}} 天前，最后一次更新在 {{updated}} 天前的文章，部分信息可能已经发生改变，请注意甄别。</p></div>`,
    quiz: {
        choice: `单选题`,
        multiple: `多选题`,
        true_false: `判断题`,
        essay: `问答题`,
        gap_fill: `填空题`,
        mistake: `错题备注`
    },
    ignores: [
        (uri) => uri.includes('#'),
        (uri) => new RegExp(LOCAL.path + '$').test(uri),
            []
    ]
};
</script><script src="https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous" fetchpriority="high"></script><script src="https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha384-ZvpUoO&#x2F;+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn&#x2F;6Z&#x2F;hRTt8+pR6L4N2" crossorigin="anonymous" fetchpriority="high"></script><script src="/js/siteInit.js?v=0.4.17" type="module" fetchpriority="high" defer></script></body></html>