<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"/><meta name="theme-color" content="#222"/><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"/><meta name="renderer" content="webkit"/><link rel="icon" type="image/ico" sizes="32x32" href="/assets/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"/><link rel="alternate" href="/rss.xml" title="NightFury" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="NightFury" type="application/atom+xml"><link rel="alternate" type="application/json" title="NightFury" href="https://nightfury.top/feed.json"/><link rel="preconnect" href="https://mirrors.sustech.edu.cn/cdnjs"/><link rel="preconnect" href="https://cdnjs.snrat.com"/><link rel="preconnect" href="https://s4.zstatic.net"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/app.css?v=0.4.17"><link rel="modulepreload" href="/js/chunk-EWPEWLLZ.js"></link><link rel="modulepreload" href="/js/chunk-FJIYN5II.js"></link><link rel="modulepreload" href="/js/chunk-M4X3XC6X.js"></link><link rel="modulepreload" href="/js/chunk-RPQFIKYV.js"></link><link rel="modulepreload" href="/js/chunk-U5IFKWJQ.js"></link><link rel="modulepreload" href="/js/chunk-WIQECBEN.js"></link><link rel="modulepreload" href="/js/comments-FXTJC3OS.js"></link><link rel="modulepreload" href="/js/copy-tex-SNESBJPB.js"></link><link rel="modulepreload" href="/js/index.esm-KW346CBT.js"></link><link rel="modulepreload" href="/js/post-S7HGICWK.js"></link><link rel="modulepreload" href="/js/quicklink-5D6BABLD.js"></link><link rel="modulepreload" href="/js/search-IUFG55LJ.js"></link><link rel="modulepreload" href="/js/siteInit.js"></link><link rel="modulepreload" href="/js/waline-BZCX4Z63.js"></link><link rel="stylesheet" href="/css/comments-3DIOODFJ.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/waline-RZIHPP7A.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="preload" href="/assets/cover/IEEE.webp" as="image" fetchpriority="high"><meta name="keywords" content="SNN,Hardware"/><meta name="description" content="个人笔记 &amp; 踩坑记录 &amp; 各种收藏"/><link rel="canonical" href="https://nightfury.top/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/"><title>Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</h1><div class="meta"><span class="item" title="创建时间：2023-09-07 20:46:18"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">发表于</span><time itemprop="dateCreated datePublished" datetime="2023-09-07T20:46:18+08:00">2023-09-07</time></span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i></span><span class="text">本文字数</span><span>4.2k</span><span class="text">字</span></span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i></span><span class="text">阅读时长</span><span>4 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">NightFury's Blog</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><img src="/assets/cover/IEEE.webp" loading="eager" decoding="async" fetchpriority="high" alt="NightFury"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemListElement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">首页</a></span><i class="ic i-angle-right"></i><span itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/Paper/" itemprop="item" rel="index" title="分类于Paper"><span itemprop="name">Paper<meta itemprop="position" content="0"/></span></a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/Paper/Algorithm/" itemprop="item" rel="index" title="分类于Algorithm"><span itemprop="name">Algorithm<meta itemprop="position" content="1"/></span></a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://nightfury.top/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/"/><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/avatar.webp"/><meta itemprop="name" content="NightFury"/><meta itemprop="description" content="行动胜于空想, 个人笔记 &amp; 踩坑记录 &amp; 各种收藏"/></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="NightFury"/></span><div class="body md" itemprop="articleBody"><div class="tabs" id="summary"><div class="show-btn"></div><div class="nav"><ul class="special"></ul></div><div class="tab" data-id="summary" data-title="自我介绍"><p>我是 Gemini-2.0-flash-exp 打造的 AI 助手，我的小脑袋瓜可厉害啦，帮你咻咻咻地概括文章重点！✨</p></div><div class="tab active" data-id="summary" data-title="文章概括"><p>这篇论文提出了一种针对稀疏激活的卷积脉冲神经网络 (CSNNs) 的高效硬件加速架构。该架构采用与卷积核大小相同的处理单元 (PE) 阵列和一个智能脉冲队列，实现了高PE利用率。通过将特征图压缩成可逐个脉冲处理的队列，实现了运行时自定时调度。此外，论文提出了一种使用多个小型并行片上RAM的高效内存组织方案来存储和检索神经元膜电位，每个RAM与对应的PE硬连线，减少了开关电路。该架构在FPGA上实现，与之前的SNN实现相比，显著提高了速度（约10倍），降低了资源占用，并实现了更高的能源效率（约15倍）。 主要创新在于针对3x3卷积的优化，包括独特的内存组织和地址计算方法。
</p></div></div><h1 id="Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks"><a href="#Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks" class="headerlink" title="Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks"></a>Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>翻译自 ChatGPT：</p>
<blockquote>
<p>脉冲神经网络（SNNs）以事件驱动方式进行计算，以实现比标准神经网络更高效的计算。在 SNNs 中，神经元的输出不是编码为实值激活，而是编码为二进制脉冲序列。使用 SNNs 而不是传统神经网络的动机根植于脉冲处理的特殊计算方面，尤其是高度稀疏的脉冲。已经建立良好的卷积神经网络（CNNs）实现具有大型的处理元素（PEs）空间阵列，但在面对激活稀疏性时，它们的利用率仍然很低。我们提出了一种针对高度稀疏的卷积脉冲神经网络（CSNNs）进行优化的新型架构。<strong>所提出的架构包括一个与卷积内核大小相同的PE阵列以及一个智能脉冲队列，提供了高PE利用率</strong>。通过将特征图压缩成可以逐个脉冲处理的队列，确保了脉冲的持续流动。这种压缩是在运行时执行的，导致了一种自时序调度。这使得处理时间可以随着脉冲数量的增加而扩展。此外，引入了一种新颖的内存组织方案，用于使用多个小型并行的片上 RAM 高效存储和检索各个神经元的膜电位。每个 RAM 都与其 PE 硬连线，减少了开关电路。我们在 FPGA 上实现了所提出的架构，并与以前提出的 SNN 实现相比实现了显著的加速（约 10 倍），同时需要更少的硬件资源并保持更高的能源效率（约 15 倍）。</p>
</blockquote>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ol>
<li>使用 <strong>m-TTFS coding</strong>，比 rate coding 时间步更短，相较于 TTFS 的只发射一次脉冲变成持续发送脉冲，虽然脉冲稀疏性降低了，但是不需要再积累膜电势了，仍然比 rate coding 更加高效。但是后面在讲 Thresholding Unit 的时候，又提到说 m-TTFS coding 只发射一次脉冲，前后矛盾！！暂且认为是笔误了，Threshoding Unit 对于膜电势做两个判断，一是是否超过阈值，二是特定的 bit 有没有 set，set 说明发射过脉冲，而在最后一个时间步时会 reset.<img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/Coding%E7%9F%9B%E7%9B%BE1.png" alt="Coding矛盾1"><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/Coding%E7%9F%9B%E7%9B%BE2.png" alt="Coding矛盾2"></li>
</ol>
<h2 id="硬件架构"><a href="#硬件架构" class="headerlink" title="硬件架构"></a>硬件架构</h2><ol>
<li>卷积和全连接分成了两个部分硬件实现，不够优雅（你猜为什么测试用例在做 FC 之前卷积核个数锐减到 10 个？），系统框图如图：<img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E7%B3%BB%E7%BB%9F%E6%A1%86%E5%9B%BE.png" alt="系统框图"></li>
<li><strong>输出通道作为循环最外层</strong>，先对某一通道做所有时间步的推理，然后将这些通道的 Spike 存入 AER 的表中。一层一层做，没有层间流水化：<img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E6%8E%A8%E7%90%86%E5%BE%AA%E7%8E%AF.png" alt="推理循环"></li>
</ol>
<h2 id="硬件实现"><a href="#硬件实现" class="headerlink" title="硬件实现"></a>硬件实现</h2><ol>
<li><p>所谓的 <strong>Memory Interlacing</strong>，就是只做 3×3 卷积（这篇文章对于 3×3 卷积做了很多特定的设计，非常之不通用，详见后文），且这 9 个格的 Spike 可以并行写入到 9 个 RAM 里作为 AER 表格（深度未知，需要 fmapSize &#x2F; 9 × ChannelOut？） 。他的分块方式是这样的：对特征图 FMap 直接做 3×3 的分块，然后将分块内的 9 个元素编号后分别存在各自的 RAM 中，膜电势和权重也是分成 9 个部分，AER 表格存储方式如图：<img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E5%86%85%E5%AD%98%E5%88%86%E5%9D%97.png" alt="内存分块"></p>
</li>
<li><p>卷积单元流程可以分为：<strong>计算地址 S1 → 读膜电势 S2 → 更新电势 S3 → 写膜电势 S4</strong>。</p>
<ul>
<li><p>计算 Spike 所产生的 Active 邻域地址的时候，作者对于 9 个输出地址与输入地址都做了相应的映射（对于 3×3 卷积设计非常的特质化！！或许有些情况可以合并，懒得深究了），如图为输入地址为(0, 0)[5]（$s_{in}&#x3D;5$）到邻域 $s_{in}&#x3D;1$ 的映射公式与示例：</p>
<p><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E9%82%BB%E5%9F%9F%E6%98%A0%E5%B0%84%E7%A4%BA%E4%BE%8B.png" alt="邻域映射示例"><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E9%82%BB%E5%9F%9F%E6%98%A0%E5%B0%84%E5%85%AC%E5%BC%8F.png" alt="邻域映射公式"></p>
<p>除此之外，由于这 9 个卷积核到 9 个 PE 的映射取决于输入脉冲地址（比如从蓝框到紫框，最左上角从序号 1 变成了序号 6，但权重位置其实没有变），所以它还需要 9 个 9 选 1 的 Mux 来做膜电势更新。 </p>
</li>
<li><p>更新电势的过程中考虑了上溢下溢的情况做了饱和操作，饱和操作对于 m-TTFS 而言影响不大，通过 <strong>check 符号位的变化</strong>可以实现上下溢的判断，好评。</p>
</li>
<li><p>卷积会遇到 S2 - S4，S3 - S4 的 <strong>Data Hazard</strong>，为了避免这样的数据冒险，作者对 S2 - S4 的数据冒险（S4 写的膜电势地址与 S2 读的膜电势地址一致）做了 Bypass（意味着 9 个 2 选 1 的 Mux），因为 S4 计算完的膜电势刚好可以对 S2 用，而对于 S3 - S4 的数据冒险则是采用了对 S2，S1 做了阻塞，从而使得转换成 S2 - S4 的数据冒险类型，但这样其实是会空一拍。不过作者也说明了由于他是 0 - 9 的顺序去做的，所以其实也很难有同样地址的 S3 - S4 数据冒险。</p>
</li>
</ul>
</li>
<li><p>只支持 3×3 的 MaxPooling，垃圾。</p>
<p><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/MaxPooling.png" alt="MaxPooling"></p>
</li>
</ol>
<h2 id="实验与总结"><a href="#实验与总结" class="headerlink" title="实验与总结"></a>实验与总结</h2><ol>
<li><p>给出了不同并行度时的吞吐速率和功耗，进一步计算能效比，这样可以选择出合适的并行度，不错的思路。</p>
<p><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E8%83%BD%E6%95%88%E6%AF%94.png" alt="能效比"></p>
</li>
<li><p>8 bits 量化大概用了 60 个 36K BRAM，16 bits 量化大概用了 111 个 36K BRAM（网络本身很小，28×28-32C3-32C3-P3-10C3-F10，对于 8 bits 量化而言按道理权重需要 10 个 18K 而已，膜电势就算所有都全存储起来也只需要 50 个 18K，你在这用了 60 个 36 K 在干啥啊？？），时钟频率跑到 333 MHz，但用的是 UltraScale+ ZU7EV，这个器件比 ZU5EV 大了一倍多，只能说还可以吧。<img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E8%B5%84%E6%BA%90%E5%88%A9%E7%94%A8%E7%8E%87.png" alt="资源利用率"></p>
</li>
<li><p>作者统计了下自己 PE 阵列的使用率，第二、三层都只有 50+ 的使用率，这依然不妨碍作者夸自己的 PE 使用率高。</p>
<p><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/PE%E4%BD%BF%E7%94%A8%E7%8E%87.png" alt="PE使用率"></p>
</li>
<li><p>性能对比：</p>
<p><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94.png" alt="性能对比"></p>
</li>
</ol>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ol>
<li><p>结论部分说自己的 neuron multiplexing 是为了降低膜电势的存储占用问题的？？？</p>
<p><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E8%BF%B7%E6%83%91.png" alt="迷惑"></p>
</li>
<li><p>通信作者是 IEEE Fellow，以及</p>
<p><img loading="lazy" data-src="/assets/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/%E6%8E%A5%E6%94%B6%E6%97%A5%E6%9C%9F.png" alt="接收日期"></p>
<p>dddd，哈哈。</p>
</li>
</ol>
<div class="tags"><a href="/tags/SNN/" rel="tag"><i class="ic i-tag"></i>SNN</a><a href="/tags/FPGA/" rel="tag"><i class="ic i-tag"></i>FPGA</a><a href="/tags/Hardware/" rel="tag"><i class="ic i-tag"></i>Hardware</a></div></div><footer><div class="meta"><span class="icon"><i class="ic i-eye"></i></span><span>此文章已被阅读次数:</span><span class="waline-pageview-count" id="twikoo_visitors" data-path="/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/">正在加载...</span><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">更新于</span><time title="修改时间：2025-01-20 18:43:13" itemprop="dateModified" datetime="2025-01-20T18:43:13+08:00">2025-01-20</time></span></div><div id="copyright"><ul><li class="author"><strong>本文作者：</strong>NightFury<i class="ic i-at"><em>@</em></i>NightFury</li><li class="link"><strong>本文链接：</strong><a href="https://nightfury.top/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/" title="Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks">https://nightfury.top/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/</a></li><li class="license"><strong>版权声明：</strong>本站所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2023/08/18/StreamFifo/" rel="prev" itemprop="url" data-background-image="&#x2F;assets&#x2F;cover&#x2F;SpinalHDL.webp" title="StreamFifo"><span class="type">上一篇</span><span class="category"><i class="ic i-flag"></i>Draft</span><h3>StreamFifo</h3></a></div><div class="item right"><a href="/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/" rel="next" itemprop="url" data-background-image="&#x2F;assets&#x2F;cover&#x2F;IEEE.webp" title="A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator"><span class="type">下一篇</span><span class="category"><i class="ic i-flag"></i>Algorithm</span><h3>A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks"><span class="toc-number">1.</span> <span class="toc-text">Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.2.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E6%9E%B6%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">硬件架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.4.</span> <span class="toc-text">硬件实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E6%80%BB%E7%BB%93"><span class="toc-number">1.5.</span> <span class="toc-text">实验与总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">1.6.</span> <span class="toc-text">结论</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li  class="active"><a href="/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/" rel="bookmark" title="Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks">Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</a></li><li ><a href="/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/" rel="bookmark" title="A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator">A Low Power and Low Latency FPGA-Based Spiking Neural Network Accelerator</a></li><li ><a href="/2023/09/11/table/" rel="bookmark" title="table">table</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="NightFury" src="/assets/avatar.webp"/><p class="name" itemprop="name">NightFury</p><div class="description" itemprop="description">个人笔记 & 踩坑记录 & 各种收藏</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">15</span><span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">7</span><span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">18</span><span class="name">标签</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/szNightFury" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;szNightFury"><i class="ic i-github"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li></div></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2023/09/10/A-Low-Power-and-Low-Latency-FPGA-Based-Spiking-Neural-Network-Accelerator/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2023/08/18/StreamFifo/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/Algorithm/" title="分类于Algorithm">Algorithm</a><i class="ic i-angle-right"></i><a href="/categories/Algorithm/Draft/" title="分类于Draft">Draft</a></div><span><a href="/2023/08/15/Memory%20Layout%20Analysis/">Memory Layout Analysis</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2024/07/05/%E5%88%A9%E7%94%A8Acme%E8%84%9A%E6%9C%AC%E8%87%AA%E5%8A%A8%E7%94%B3%E8%AF%B7SSL%E8%AF%81%E4%B9%A6/">利用Acme脚本自动申请SSL证书</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Paper/" title="分类于Paper">Paper</a><i class="ic i-angle-right"></i><a href="/categories/Paper/Algorithm/" title="分类于Algorithm">Algorithm</a></div><span><a href="/2023/09/11/table/">table</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2023/08/13/Markdown%E5%9B%BE%E7%89%87%E9%85%8D%E7%BD%AE/">Markdown图片配置</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2024/07/04/Debian12%E9%85%8D%E7%BD%AENginx1.22%E4%B8%8EPhp8.2/">Debian12配置Nginx1.22与Php8.2</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2024/07/05/Debian12%E9%83%A8%E7%BD%B2Cloudreve%E4%BA%91%E7%9B%98/">Debian12部署Cloudreve云盘</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2023/07/27/HelloWorld/">Hello World</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Paper/" title="分类于Paper">Paper</a><i class="ic i-angle-right"></i><a href="/categories/Paper/Algorithm/" title="分类于Algorithm">Algorithm</a></div><span><a href="/2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/">Efficient Hardware Acceleration of Sparsely Active Convolutional Spiking Neural Networks</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2023/07/27/Php%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">Php环境配置</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Configuration/" title="分类于Configuration">Configuration</a></div><span><a href="/2023/08/14/Hexo%E9%83%A8%E7%BD%B2%E5%88%B0VPS/">Hexo部署到VPS</a></span></li></ul></div><div class="rpost pjax"><h2>最新评论</h2><ul class="leancloud-recent-comment" id="new-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2023 -<span itemprop="copyrightYear">2025</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">NightFury @ NightFury's Blog</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="站点总字数">57k 字</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="站点阅读时长">51 分钟</span></div><div class="powered-by">基于 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
        path: `2023/09/07/Efficient-Hardware-Acceleration-of-Sparsely-Active-Convolutional-Spiking-Neural-Networks/`,
        favicon: {
        show: `NightFury's Blog`,
        hide: `NightFury's Blog`
    },
    search: {
        placeholder: "文章搜索",
        empty: "关于 「 ${query} 」，什么也没搜到",
        stats: "${time} ms 内找到 ${hits} 条结果"
    },
    copy_tex: true,
    katex: true,
    mermaid: false,
    audio: undefined,
    fancybox: true,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">文章时效性提示</span><br>这是一篇发布于 {{publish}} 天前，最后一次更新在 {{updated}} 天前的文章，部分信息可能已经发生改变，请注意甄别。</p></div>`,
    quiz: {
        choice: `单选题`,
        multiple: `多选题`,
        true_false: `判断题`,
        essay: `问答题`,
        gap_fill: `填空题`,
        mistake: `错题备注`
    },
    ignores: [
        (uri) => uri.includes('#'),
        (uri) => new RegExp(LOCAL.path + '$').test(uri),
            []
    ]
};
</script><script src="https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous" fetchpriority="high"></script><script src="https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha384-ZvpUoO&#x2F;+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn&#x2F;6Z&#x2F;hRTt8+pR6L4N2" crossorigin="anonymous" fetchpriority="high"></script><script src="/js/siteInit.js?v=0.4.17" type="module" fetchpriority="high" defer></script></body></html>